# IBM Professional Data Science Certificate

Projects from the [Professional Data Science Certificate](https://www.coursera.org/professional-certificates/ibm-data-science/) from [IBM](https://www.ibm.com/) offered by [Coursera](https://coursera.org/).

## Contents

**Applied Data Science Capstone:** This is the final project of the certification:
1.  Connected to the SpaceX API, fetched data, and cleaned it up for processing.
2.  Extracted a Falcon 9 launch records HTML table from Wikipedia, then parsed the table using BeautifulSoup and converted it into a Pandas data frame.
3.  Conducted Exploratory Data Analysis using numpy and pandas. Experimental launch parameters such as orbit type, payload mass, and booster type were investigated to determine training labels for the data.
4.  Loaded the data into a Db2 database. Carried out various SQL queries to further the understanding of Falcon 9 launch outcomes.
5.  Data Visualization: Continued Exploratory Data Analysis and performed Feature Engineering with Matplotlib and pandas.
6.  Generated interactive visual analytics through the use of Folium to visualize geographical patterns among various launch sites.
7.  Created a Plotly Dash Application for users to perform interactive visual analytics on SpaceX launch data in real time.
8.  Performed additional exploratory data analyses and created additional visualizations with numpy, pandas, seaborn, and Matplotlib. Standardized and split the data into test and training sets. Utilized scikit-learn to find the best hyperparameters for various Machine Learning algorithms. Here, the Decision Tree Classification Algorithm performed best.

**Course Projects:** This directory contains final deliverables for courses in this certification:

1.  Visualized Historical Automobile Sales Data: Converted a .csv file containing the data set to a pandas dataframe. Bar, pie, and line charts were generated with seaborn and Matplotlib. Geographical visualizations were carried out with Folium. Next, a Dash Application that acts as a visual dashboard for the data was created. It compares historical sales data, allowing users to visualize trends during and outside of recession periods.
2.  Explored the stock and revenue data of Tesla and GME. Utilized yFinance to extract stock data. Obtained revenue data with Webscraping via BeautifulSoup. Stock and revenue data were plotted using plotly.
3.  House Sales in King County, USA: The dataset used here includes sales made between May 2014 and May 2015. A .csv file containing the dataset was converted to a pandas dataframe. Employed Data Wrangling to clean up the dataframe. Utilized seaborn to generate various plots to visualize the dataset. Fitted regression models to predict various home parameters. Evaluated and refined several scikit-learn models fitted to the data.
4.  Analyzed Socioeconomic Data from the City of Chicago. The datasets explored were socioeconomic indicators, public school data, and crime data. Subsequent SQL queries were performed to refine understanding of each dataset.